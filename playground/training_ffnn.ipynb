{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchmetrics import HingeLoss, MeanSquaredError\n",
    "from torchmetrics.classification import BinaryHingeLoss\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from torch.autograd.functional import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "        k: int = 3,\n",
    "        n: int = 20,\n",
    "        ):\n",
    "    parity_bits = random.sample(range(n), k)\n",
    "    num = 2 ** n\n",
    "    x = torch.zeros((num, n), dtype=torch.float32)\n",
    "    for i in range(num):\n",
    "        x[i] = torch.tensor(\n",
    "            list(map(int, bin(i)[2:].zfill(n))), dtype=torch.float\n",
    "            )\n",
    "    y = x[:, parity_bits].sum(dim=1) % 2\n",
    "    # y = 2 * y - 1\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    return x, y, parity_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHingeLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyHingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        y_hat = output\n",
    "        y_true = target * 2 - 1\n",
    "        hinge_loss = 1 - torch.mul(y_hat, y_true)\n",
    "        hinge_loss = torch.clamp(hinge_loss, min=0)\n",
    "        return (hinge_loss ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, n, k: int = 3):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(out_features=k, in_features=n),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features=1, in_features=k),\n",
    "        )\n",
    "        self.initialize_params(k, n)\n",
    "        self.freeze_params()\n",
    "\n",
    "    def initialize_params(self, k, n):\n",
    "        with torch.no_grad():\n",
    "            first_layer = self.network[0]\n",
    "            first_layer.bias.data = -torch.arange(k).float() - 0.5\n",
    "            # first_layer.weight.data = torch.ones(k, n) * k / n\n",
    "            weight_matrix = torch.Tensor([[0.9, 0, 1.2],[0.7, -0.1, 1.1]]).float()\n",
    "            first_layer.weight.data = weight_matrix\n",
    "            second_layer = self.network[2]\n",
    "            weights = torch.tensor(\n",
    "                [((-1) ** i) * (2 + 4 * i) for i in range(k)],\n",
    "                dtype=torch.float32\n",
    "                )\n",
    "            second_layer.weight.data = weights.view(1, -1)  # Shape: (k, 1)\n",
    "            second_layer.bias.data = torch.Tensor([0])\n",
    "\n",
    "    def freeze_params(self):\n",
    "        self.network[0].bias.requires_grad = False\n",
    "        self.network[0].weight.requires_grad = True\n",
    "        self.network[2].weight.requires_grad = False\n",
    "        self.network[2].bias.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 3\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, y):\n",
    "    pred = model(x)\n",
    "    predicted_classes = (pred >= 0.5).float()\n",
    "    correct_predictions = (predicted_classes == y).sum()\n",
    "    accuracy = correct_predictions / y.size(0)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 30000\n",
    "# loss_fn = BinaryHingeLoss(squared=True)\n",
    "loss_fn = HingeLoss(task=\"binary\")\n",
    "# loss_fn = MyHingeLoss()\n",
    "# loss_fn = MeanSquaredError()\n",
    "x, y, bits = data_generator(k, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNN(length, k)\n",
    "\n",
    "print(f\"the weight in the first layer is {model.network[0].weight.data}\")\n",
    "print(f\"the bias in the first layer is {model.network[0].bias.data}\")\n",
    "\n",
    "print(f\"the weight in the second layer is {model.network[2].weight.data}\")\n",
    "print(f\"the bias in the second layer is {model.network[2].bias.data}\")\n",
    "\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, shuffle=True)\n",
    "\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#     lr=4e-3\n",
    "# )\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 3e-2)\n",
    "model.train()\n",
    "weight_history = []\n",
    "loss_history = []\n",
    "gradient_norm_history = []\n",
    "for i in range(epochs):\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    current_weight = model.network[0].weight.detach().cpu().clone()\n",
    "    weight_history.append(current_weight)\n",
    "    if i % 200 == 0:\n",
    "        grad_norm = model.network[0].weight.grad.norm().item()\n",
    "        gradient_norm_history.append(grad_norm)\n",
    "        loss_history.append(loss.item())\n",
    "        print(f\"epoch {i}: loss = {loss.item():.6f}\")\n",
    "\n",
    "model.eval()\n",
    "print(test(model, x, y))\n",
    "    \n",
    "W = torch.stack(weight_history).numpy()\n",
    "\n",
    "fig, axes = plt.subplots(k, length, figsize=(10, 5))\n",
    "for i in range(k):\n",
    "    for j in range(length):\n",
    "        axes[i, j].plot(W[:, i, j])\n",
    "        axes[i, j].set_title(f\"W[{i},{j}]\")\n",
    "        axes[i, j].set_xlabel(\"Epoch\")\n",
    "        axes[i, j].set_ylabel(\"Value\")\n",
    "\n",
    "# for j in range(length):\n",
    "#     axes[j].plot(W[:, j])\n",
    "#     axes[j].set_title(f\"W[{j}]\")\n",
    "#     axes[j].set_xlabel(\"Epoch\")\n",
    "#     axes[j].set_ylabel(\"Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs_range = range(len(loss_history))\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color='tab:blue')\n",
    "ax1.plot(epochs_range, loss_history, label='Loss', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Gradient Norm', color='tab:red')\n",
    "ax2.plot(epochs_range, gradient_norm_history, label='Grad Norm', color='tab:red')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title(\"Loss and Gradient Norm over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.network[0].weight.view(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_loss_landscape(ffnn_model, inputs, targets, weight_idx1, weight_idx2, \n",
    "                        weight_range=0.5, steps=30):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        best_params = list(ffnn_model.network[0].weight.view(-1)).copy()\n",
    "        base_tensor = ffnn_model.network[0].weight.view(-1).detach().clone()\n",
    "\n",
    "    x_vals = np.linspace(-weight_range, weight_range, steps)\n",
    "    y_vals = np.linspace(-weight_range, weight_range, steps)\n",
    "    X, Y = np.meshgrid(x_vals, y_vals)\n",
    "    Z = np.zeros_like(X)\n",
    "\n",
    "    for i in range(steps):\n",
    "        for j in range(steps):\n",
    "            modified_weights = base_tensor.clone()\n",
    "\n",
    "            modified_weights[weight_idx1] += x_vals[i]\n",
    "            modified_weights[weight_idx2] += y_vals[j]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ffnn_model.network[0].weight.view(-1).copy_(modified_weights)\n",
    "\n",
    "            pred = ffnn_model(inputs)\n",
    "            loss = loss_fn(pred, targets)\n",
    "            Z[j, i] = loss.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ffnn_model.network[0].weight.view(-1).copy_(base_tensor)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    ax.set_xlabel(f'Weight {weight_idx1} offset')\n",
    "    ax.set_ylabel(f'Weight {weight_idx2} offset')\n",
    "    ax.set_zlabel('Loss')\n",
    "    ax.set_title(f'Loss landscape for weights {weight_idx1} and {weight_idx2}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_landscape(model, x, y, 0, 1)\n",
    "plot_loss_landscape(model, x, y, 2, 3)\n",
    "plot_loss_landscape(model, x, y, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import hessian\n",
    "import numpy as np\n",
    "\n",
    "def classify_critical_point(model, inputs, targets):\n",
    "    model.eval()\n",
    "\n",
    "    weight_tensor = model.network[0].weight\n",
    "    weight_flat = weight_tensor.view(-1).detach().clone().requires_grad_(True)\n",
    "\n",
    "    def loss_fn_for_hessian(w_flat):\n",
    "        w_tensor = w_flat.view_as(weight_tensor)\n",
    "        with torch.no_grad():\n",
    "            model.network[0].weight.copy_(w_tensor)\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        return loss\n",
    "\n",
    "    H = hessian(loss_fn_for_hessian, weight_flat)\n",
    "    H_np = H.detach().cpu().numpy()\n",
    "\n",
    "    eigenvalues = np.linalg.eigvalsh(H_np)\n",
    "\n",
    "\n",
    "    print(f\"Top Hessian eigenvalue: {eigenvalues.max():.4e}\")\n",
    "    print(f\"Smallest Hessian eigenvalue: {eigenvalues.min():.4e}\")\n",
    "    return eigenvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_critical_point(model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = MyHingeLoss()\n",
    "a = loss_fn(pred, y)\n",
    "print(a.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uhat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
